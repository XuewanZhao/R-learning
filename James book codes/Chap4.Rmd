---
title: "Char 4 Classification"
author: "Xuewan"
output:
  html_document:
    df_print: paged
---

In this chapter, we are going to compare some classification methods:
Logistic regression; LDA; QDA; KNN.

```{r}
# import data
library(ISLR)
# import data for SP 500
names(Smarket)
dim(Smarket)
summary(Smarket)
cor(Smarket[1:8])
plot(Smarket$Volume)
```

## Logistic regression.
Regression on whole dataset.
```{r}
# We use generalized linear regression to do logistic regression.
glm.fit = glm(Direction ~ Lag1+ Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Smarket, family = binomial)
summary(glm.fit)

# Show coefficients.
coef(glm.fit)
summary(glm.fit)$coef

# Do prediction.
glm.proba = predict(glm.fit, type = "response")
glm.proba[1:10]

# Check qualitative levels
contrasts(Smarket$Direction)

# We output the qualitative predicition according to probability prediction.
glm.pred = rep("Down", dim(Smarket)[1])
glm.pred[glm.proba > 0.5] = "Up"

# We use table() function to produce a confusion matrix.
table(glm.pred, Smarket$Direction)

# Total training error rate
mean(glm.pred != Smarket$Direction)
```

Test strategy by splitting training and test sets.

```{r}
train = Smarket$Year < 2005 # a vector of size 1250, containing True and False.
Smarket.2005 = Smarket[!train,]
dim(Smarket.2005)

# Training our model during 2001-2004
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
            data=Smarket ,family=binomial,subset=train)
glm.proba = predict(glm.fit, Smarket.2005, type = "response")

# Test our model on test set.
# We convert probability into qualitative values.
glm.pred = rep("Down", dim(Smarket.2005)[1])
glm.pred[glm.proba > 0.5] = "Up"
table(glm.pred, Smarket.2005$Direction)
# Check the correct rate.
mean(glm.pred==Smarket.2005$Direction)

# We try to remove insignificate predictors and then train model again.
glm.fit=glm(Direction~Lag1+Lag2,data=Smarket ,family=binomial ,
subset=train)
glm.probs=predict(glm.fit,Smarket.2005,type="response")
glm.pred=rep("Down",252)
glm.pred[glm.probs >.5]="Up"
table(glm.pred,Smarket.2005$Direction)
# Check the correct rate.
mean(glm.pred==Smarket.2005$Direction)

# Do prediction with user-defined data.
predict(glm.fit,newdata=data.frame(Lag1=c(1.2,1.5),
Lag2=c(1.1,-0.8)),type="response")
```

## Linear Discriminant Analysis( LDA )

```{r}
# LDA method is in library MASS
library(MASS)
lda.fit=lda(Direction~Lag1+Lag2,data=Smarket ,subset=train)
lda.fit
plot(lda.fit)
```

If ???0.642¡ÁLag1???0.514¡ÁLag2 is large, then the LDA classi???er will predict a market increase, and if it is small, then the LDA classi???er will predict a market decline. The plot() function produces plots of the linear discriminants, obtained by computing ???0.642 ¡Á Lag1 ??? 0.514 ¡Á Lag2 for each of the training observations.
 
The predict() function returns a list with three elements. The ???rst ele-ment, class, contains LDA¡¯s predictions about the movement of the market.
The second element, posterior, is a matrix whose kth column contains the posterior probability that the corresponding observation belongs to the kth class, computed from (4.10). Finally, x contains the linear discriminants, described earlier.

```{r}
lda.pred=predict(lda.fit, Smarket.2005)
names(lda.pred)

lda.class=lda.pred$class
table(lda.class ,Smarket.2005$Direction)

mean(lda.class==Smarket.2005$Direction)

sum(lda.pred$posterior[,1]>=.5) # 1 down prob, 2 up prob
sum(lda.pred$posterior[,1]<.5)

# Change threshold.
sum(lda.pred$posterior[,1]>.9)
```
 
 ## Quadratic Discriminant Analysis ( QDA )
```{r}
# qda is in library MASS
qda.fit=qda(Direction~Lag1+Lag2,data=Smarket ,subset=train)
qda.fit

qda.class=predict(qda.fit,Smarket.2005)$class
table(qda.class ,Smarket.2005$Direction)

mean(qda.class==Smarket.2005$Direction)
```
 
 ## K-Nearest Neighbors (KNN)
```{r}
# This function knn() in from library class
library(class)

# Create training set and test set.
train.X=cbind(Smarket$Lag1,Smarket$Lag2)[train ,]
test.X=cbind(Smarket$Lag1,Smarket$Lag2)[!train ,]
train.Direction = Smarket[train,]$Direction

# Try knn, k=1
set.seed(1)
knn.pred=knn(train.X,test.X,train.Direction ,k=1)
table(knn.pred,Smarket.2005$Direction)
mean(knn.pred == Smarket.2005$Direction)

# Try knn, k=3
set.seed(1)
knn.pred=knn(train.X,test.X,train.Direction ,k=3)
table(knn.pred,Smarket.2005$Direction)
mean(knn.pred == Smarket.2005$Direction)
```
 
## Caravan issurance application.

```{r}
dim(Caravan)
attach(Caravan)
summary(Purchase)

# We standardize the columns.
standardized.X= scale(Caravan[,-86])
var(Caravan [ ,1])
var(Caravan [ ,2])
var(standardized.X[,1])
var(standardized.X[,2])

test=1:1000
train.X= standardized.X[-test,]
test.X= standardized.X[test,]
train.Y=Purchase[-test]
test.Y=Purchase[test]
set.seed(1)
knn.pred=knn(train.X,test.X,train.Y,k=1)
# Correction rate.
mean(test.Y==knn.pred)

table(knn.pred,test.Y)

# K = 3
knn.pred=knn(train.X,test.X,train.Y,k=3)
table(knn.pred,test.Y)
mean(test.Y==knn.pred)

# K = 4
knn.pred=knn(train.X,test.X,train.Y,k=5)
table(knn.pred,test.Y)
mean(test.Y==knn.pred)

# Compare with Logistic regression.
glm.fit=glm(Purchase~.,data=Caravan,family=binomial,subset=-test)

glm.probs=predict(glm.fit,Caravan[test ,], type="response")
glm.pred=rep("No",tail(test,1))
glm.pred[glm.probs >.5]="Yes"
table(glm.pred,test.Y)

# Now we release the threshold.
glm.pred[glm.probs >.25]=" Yes"
table(glm.pred,test.Y)

```

Our accuracy on 'Puchasement' is highly improved to be 33%.








